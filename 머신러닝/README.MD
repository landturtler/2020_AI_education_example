#### 파이썬 활용 머신러닝


- Kaggle

    https://www.kaggle.com/


- UCI Machine Learning Repository (머신러닝 데이터)
    
    https://archive.ics.uci.edu/ml/index.php
    
    
- 데이콘 (경진대회)   
    https://dacon.io/
    
    
#### 딥러닝 강좌  

- 모두를 위한 머신러닝과 딥러닝의 강의(김성훈교수님)

    https://hunkim.github.io/ml/


인공지능의 역사 : 신경망(DNN,Deep Neural Net) 역사
* (1) 퍼셉트론 : 다수의 신호를 입력받아서 하나의 신호로 출력, 신경망의 기원이 되는 알고리즘,
Frank Rosenblatt(1957,Cornell Aeronautical Lab 알고리즘 개발)
* (2) XOR Problem : Marvin Minsky(1969,MIT AI Lab founder)
퍼셉트론은 AND, OR, NAND 같은 선형문제는 풀수 있을지 모르지만, XOR같은 비선형 문제를 풀수가 없다--> 인공지능의 1차 겨울
* (3) Backpropagation : 1986년 제프리 힌튼(Geoffrey Hinton)
샘플에 대한 신경망의 오차를 다시 출력층에서부터 입력층으로 거꾸로 전파시켜 각 층의 가중치(weight)를 계산하는 방법. 이를 통해 weight와 bias를 알맞게 학습할 수 있다
* (4) 두 번째 겨울(빙하기) : 1990년대 후반
1. Vanishing Gradient : 신경망의 깊이가 깊어질수록 원하는 결과를 얻을 수 없다
2. 신경망 학습을 위한 파라미터 값의 최적화에 대한 이론적인 근거가 없었다.
* (5) Deep의 출현 : 2006년 , Geoffrey Hinton, "A fast learning algorithm for deep belief nets" 라는 논문
weight의 초기값을 제대로 설정하면 깊은 신경망학습이 가능하다 neural networke 대신 Deep Network, Deep Learning 이라는 용어가 사용되기 시작했다.

